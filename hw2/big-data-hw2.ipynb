{"cells":[{"cell_type":"markdown","metadata":{"id":"cyvVAJoLcFMU"},"source":["# 第 11 組 HW2 程式作業"]},{"cell_type":"markdown","source":["## 組員名單\n","\n","- 資工三 109590010 林敬翔\n","- 資工三 109590011 陳彥宇\n","- 資工三 109590026 黃亮維"],"metadata":{"id":"xWqauVcgjGrT"}},{"cell_type":"markdown","source":["按照順序執行即可"],"metadata":{"id":"Lks6lIVGNVzr"}},{"cell_type":"markdown","metadata":{"id":"3fJKV0GWS8Dw"},"source":["## 6.7 Using a programming language that you are familiar with, such as C++ or Java, implement the following frequent itemset mining algorithms introduced in this chapter:"]},{"cell_type":"code","source":["# 下載 kaggle Apriori Algorithm 資料集\n","# https://www.kaggle.com/code/xinyidai/apriori-algorithm/data\n","!pip install gdown\n","!gdown 1PbGaP4SFbvXfaZyMVMsR17i-A3NpsAwt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4CRU-SbI2-P","executionInfo":{"status":"ok","timestamp":1667791074122,"user_tz":-480,"elapsed":10118,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"outputId":"50710343-dcfe-45f3-a544-82fe48b0f603"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From: https://drive.google.com/uc?id=1PbGaP4SFbvXfaZyMVMsR17i-A3NpsAwt\n","To: /content/GroceryStoreDataSet.csv\n","100% 478/478 [00:00<00:00, 606kB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"cJPNuK1sTE4s"},"source":["### (1) Apriori"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from itertools import combinations, chain"],"metadata":{"id":"rveXNnqq2wl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def powerset(s):\n","    return list(chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1)))\n","def count_occurences(item, transactions):\n","    temp = 0\n","    for i in range(len(transactions)):\n","        if set(item).issubset(set(transactions[i])):\n","            temp += 1\n","    return temp\n","\n","def join_two_itemsets(it1, it2, order):\n","    it1.sort(key=lambda x:order.index(x))\n","    it2.sort(key=lambda x:order.index(x))\n","\n","    for i in range(len(it1) - 1):\n","        if it1[i] != it2[i]:\n","            return []\n","    if order.index(it1[-1]) < order.index(it2[-1]):\n","        return it1 + [it2[-1]]\n","    return []\n","\n","def join_set_itemsets(set_of_its, order):\n","    C = []\n","    for i in range(len(set_of_its)):\n","        for j in range(i+1, len(set_of_its)):\n","            it_out = join_two_itemsets(set_of_its[i], set_of_its[j], order)\n","            if len(it_out) > 0:\n","                C.append(it_out)\n","    return C\n","\n","\n","def get_frequent( itemsets, transactions, min_support, prev_discarded):\n","    LG = []\n","    supp_count = []\n","    new_discarded = []\n","\n","    k = len(prev_discarded.keys())\n","\n","    for s in range(len(itemsets)):\n","        discarded_before = False\n","        if k > 0:\n","            for it in prev_discarded[k]:\n","                if set(it).issubset(set(itemsets[s])):\n","                    discarded_before = True\n","                    break\n","\n","        if not discarded_before:\n","            count = count_occurences(itemsets[s], transactions)\n","            if count/len(transactions) >= min_support:\n","                LG.append(itemsets[s])\n","                supp_count.append(count)\n","            else:\n","                new_discarded.append(itemsets[s])\n","\n","    return LG,supp_count,new_discarded\n","\n","def write_rules(X, X_S, S, conf, supp, lift, num_transactions):\n","    out_rules = \"\"\n","    out_rules += \"Freq. Itemset: {} \\n\".format(X)\n","    out_rules += \"   Rule: {} -> {} \\n\".format(list(S), list(X_S))\n","    out_rules += \"   Conf: {0:2.3f} \".format(conf)\n","    out_rules += \"   Supp: {0:2.3f} \".format(supp / num_transactions)\n","    out_rules += \"   Lift: {0:2.3f} \".format(lift)\n","    out_rules += \"\\n\"\n","    return out_rules"],"metadata":{"id":"5qm86m-S9EpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('GroceryStoreDataSet.csv',header=None)\n","transactions = []\n","for i in df[0]:\n","    j = (i.split(','))\n","    transactions.append(j)\n","num_trans = len(transactions)"],"metadata":{"id":"i_CEBDZr9HVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["C = {}\n","L = {}\n","itemset_size = 1\n","discarded = {itemset_size : []}\n","order = []\n","for i in transactions:\n","    for j in i:\n","        if(j not in order):\n","            order.append(j)\n","order = sorted(order)\n","C.update({itemset_size : [ [f] for f in order]})\n","supp_count_L = {}\n","min_support = 0.1\n","min_conf = 0.1\n","f, sup, new_discarded = get_frequent(C[itemset_size], transactions, min_support, discarded)\n","discarded.update({itemset_size :  new_discarded})\n","L.update({itemset_size : f})\n","supp_count_L.update({itemset_size : sup})\n"],"metadata":{"id":"tvunNtKk9KXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k = itemset_size + 1\n","convergence = False\n","while not convergence:\n","    C.update({ k : join_set_itemsets(L[k-1], order)})\n","\n","    f , sup, new_discarded = get_frequent(C[k], transactions, min_support, discarded)\n","    discarded.update({k : new_discarded})\n","    L.update({k : f})\n","    supp_count_L.update({k : sup})\n","    \n","    if len(L[k]) == 0:\n","        convergence = True\n","    k += 1\n"],"metadata":{"id":"vpgRONED9MbY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["assoc_rules_str =\"\"\n","for i in range(1, len(L)):\n","    for j in range(len(L[i])):\n","        s = list(powerset(set(L[i][j])))\n","        s.pop()\n","        for z in s:\n","            S =set(z)\n","            X = set(L[i][j])\n","            X_S = set(X-S)\n","            sup_x = count_occurences(X, transactions)\n","            sup_x_s = count_occurences(X_S, transactions)\n","            conf = sup_x / count_occurences(S, transactions)\n","            lift = conf /(sup_x_s/ num_trans)\n","            if conf >= min_conf and sup_x >= min_support:\n","                assoc_rules_str += write_rules(X, X_S, S, conf, sup_x, lift, num_trans)\n","            "],"metadata":{"id":"FCNdqIU__ijc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 顯示頻繁項集與關連規則\n","print(assoc_rules_str)"],"metadata":{"id":"4yZf66Nv_jE8","executionInfo":{"status":"ok","timestamp":1667791387956,"user_tz":-480,"elapsed":3,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"outputId":"ce37d533-19e5-48b4-840b-6d80bd59e6c1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Freq. Itemset: {'BISCUIT', 'BREAD'} \n","   Rule: ['BISCUIT'] -> ['BREAD'] \n","   Conf: 0.571    Supp: 0.200    Lift: 0.879 \n","Freq. Itemset: {'BISCUIT', 'BREAD'} \n","   Rule: ['BREAD'] -> ['BISCUIT'] \n","   Conf: 0.308    Supp: 0.200    Lift: 0.879 \n","Freq. Itemset: {'BISCUIT', 'COCK'} \n","   Rule: ['BISCUIT'] -> ['COCK'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'BISCUIT', 'COCK'} \n","   Rule: ['COCK'] -> ['BISCUIT'] \n","   Conf: 0.667    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'BISCUIT', 'COFFEE'} \n","   Rule: ['BISCUIT'] -> ['COFFEE'] \n","   Conf: 0.286    Supp: 0.100    Lift: 0.714 \n","Freq. Itemset: {'BISCUIT', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['BISCUIT'] \n","   Conf: 0.250    Supp: 0.100    Lift: 0.714 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES'} \n","   Rule: ['BISCUIT'] -> ['CORNFLAKES'] \n","   Conf: 0.429    Supp: 0.150    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES'} \n","   Rule: ['CORNFLAKES'] -> ['BISCUIT'] \n","   Conf: 0.500    Supp: 0.150    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'MAGGI'} \n","   Rule: ['BISCUIT'] -> ['MAGGI'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.143 \n","Freq. Itemset: {'BISCUIT', 'MAGGI'} \n","   Rule: ['MAGGI'] -> ['BISCUIT'] \n","   Conf: 0.400    Supp: 0.100    Lift: 1.143 \n","Freq. Itemset: {'BISCUIT', 'MILK'} \n","   Rule: ['BISCUIT'] -> ['MILK'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.143 \n","Freq. Itemset: {'BISCUIT', 'MILK'} \n","   Rule: ['MILK'] -> ['BISCUIT'] \n","   Conf: 0.400    Supp: 0.100    Lift: 1.143 \n","Freq. Itemset: {'BISCUIT', 'TEA'} \n","   Rule: ['BISCUIT'] -> ['TEA'] \n","   Conf: 0.286    Supp: 0.100    Lift: 0.816 \n","Freq. Itemset: {'BISCUIT', 'TEA'} \n","   Rule: ['TEA'] -> ['BISCUIT'] \n","   Conf: 0.286    Supp: 0.100    Lift: 0.816 \n","Freq. Itemset: {'BREAD', 'BOURNVITA'} \n","   Rule: ['BREAD'] -> ['BOURNVITA'] \n","   Conf: 0.231    Supp: 0.150    Lift: 1.154 \n","Freq. Itemset: {'BREAD', 'BOURNVITA'} \n","   Rule: ['BOURNVITA'] -> ['BREAD'] \n","   Conf: 0.750    Supp: 0.150    Lift: 1.154 \n","Freq. Itemset: {'SUGER', 'BOURNVITA'} \n","   Rule: ['SUGER'] -> ['BOURNVITA'] \n","   Conf: 0.333    Supp: 0.100    Lift: 1.667 \n","Freq. Itemset: {'SUGER', 'BOURNVITA'} \n","   Rule: ['BOURNVITA'] -> ['SUGER'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.667 \n","Freq. Itemset: {'TEA', 'BOURNVITA'} \n","   Rule: ['TEA'] -> ['BOURNVITA'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'TEA', 'BOURNVITA'} \n","   Rule: ['BOURNVITA'] -> ['TEA'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BREAD', 'COFFEE'} \n","   Rule: ['BREAD'] -> ['COFFEE'] \n","   Conf: 0.231    Supp: 0.150    Lift: 0.577 \n","Freq. Itemset: {'BREAD', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['BREAD'] \n","   Conf: 0.375    Supp: 0.150    Lift: 0.577 \n","Freq. Itemset: {'JAM', 'BREAD'} \n","   Rule: ['JAM'] -> ['BREAD'] \n","   Conf: 1.000    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'JAM', 'BREAD'} \n","   Rule: ['BREAD'] -> ['JAM'] \n","   Conf: 0.154    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'MAGGI', 'BREAD'} \n","   Rule: ['MAGGI'] -> ['BREAD'] \n","   Conf: 0.600    Supp: 0.150    Lift: 0.923 \n","Freq. Itemset: {'MAGGI', 'BREAD'} \n","   Rule: ['BREAD'] -> ['MAGGI'] \n","   Conf: 0.231    Supp: 0.150    Lift: 0.923 \n","Freq. Itemset: {'MILK', 'BREAD'} \n","   Rule: ['MILK'] -> ['BREAD'] \n","   Conf: 0.800    Supp: 0.200    Lift: 1.231 \n","Freq. Itemset: {'MILK', 'BREAD'} \n","   Rule: ['BREAD'] -> ['MILK'] \n","   Conf: 0.308    Supp: 0.200    Lift: 1.231 \n","Freq. Itemset: {'SUGER', 'BREAD'} \n","   Rule: ['SUGER'] -> ['BREAD'] \n","   Conf: 0.667    Supp: 0.200    Lift: 1.026 \n","Freq. Itemset: {'SUGER', 'BREAD'} \n","   Rule: ['BREAD'] -> ['SUGER'] \n","   Conf: 0.308    Supp: 0.200    Lift: 1.026 \n","Freq. Itemset: {'TEA', 'BREAD'} \n","   Rule: ['TEA'] -> ['BREAD'] \n","   Conf: 0.571    Supp: 0.200    Lift: 0.879 \n","Freq. Itemset: {'TEA', 'BREAD'} \n","   Rule: ['BREAD'] -> ['TEA'] \n","   Conf: 0.308    Supp: 0.200    Lift: 0.879 \n","Freq. Itemset: {'COCK', 'COFFEE'} \n","   Rule: ['COCK'] -> ['COFFEE'] \n","   Conf: 1.000    Supp: 0.150    Lift: 2.500 \n","Freq. Itemset: {'COCK', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['COCK'] \n","   Conf: 0.375    Supp: 0.150    Lift: 2.500 \n","Freq. Itemset: {'COCK', 'CORNFLAKES'} \n","   Rule: ['COCK'] -> ['CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'COCK', 'CORNFLAKES'} \n","   Rule: ['CORNFLAKES'] -> ['COCK'] \n","   Conf: 0.333    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'CORNFLAKES', 'COFFEE'} \n","   Rule: ['CORNFLAKES'] -> ['COFFEE'] \n","   Conf: 0.667    Supp: 0.200    Lift: 1.667 \n","Freq. Itemset: {'CORNFLAKES', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['CORNFLAKES'] \n","   Conf: 0.500    Supp: 0.200    Lift: 1.667 \n","Freq. Itemset: {'SUGER', 'COFFEE'} \n","   Rule: ['SUGER'] -> ['COFFEE'] \n","   Conf: 0.667    Supp: 0.200    Lift: 1.667 \n","Freq. Itemset: {'SUGER', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['SUGER'] \n","   Conf: 0.500    Supp: 0.200    Lift: 1.667 \n","Freq. Itemset: {'MILK', 'CORNFLAKES'} \n","   Rule: ['MILK'] -> ['CORNFLAKES'] \n","   Conf: 0.400    Supp: 0.100    Lift: 1.333 \n","Freq. Itemset: {'MILK', 'CORNFLAKES'} \n","   Rule: ['CORNFLAKES'] -> ['MILK'] \n","   Conf: 0.333    Supp: 0.100    Lift: 1.333 \n","Freq. Itemset: {'TEA', 'CORNFLAKES'} \n","   Rule: ['TEA'] -> ['CORNFLAKES'] \n","   Conf: 0.286    Supp: 0.100    Lift: 0.952 \n","Freq. Itemset: {'TEA', 'CORNFLAKES'} \n","   Rule: ['CORNFLAKES'] -> ['TEA'] \n","   Conf: 0.333    Supp: 0.100    Lift: 0.952 \n","Freq. Itemset: {'MAGGI', 'JAM'} \n","   Rule: ['MAGGI'] -> ['JAM'] \n","   Conf: 0.400    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'MAGGI', 'JAM'} \n","   Rule: ['JAM'] -> ['MAGGI'] \n","   Conf: 1.000    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'MAGGI', 'TEA'} \n","   Rule: ['MAGGI'] -> ['TEA'] \n","   Conf: 0.800    Supp: 0.200    Lift: 2.286 \n","Freq. Itemset: {'MAGGI', 'TEA'} \n","   Rule: ['TEA'] -> ['MAGGI'] \n","   Conf: 0.571    Supp: 0.200    Lift: 2.286 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['BISCUIT'] -> ['MILK', 'BREAD'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['MILK'] -> ['BISCUIT', 'BREAD'] \n","   Conf: 0.400    Supp: 0.100    Lift: 2.000 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['BREAD'] -> ['BISCUIT', 'MILK'] \n","   Conf: 0.154    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['BISCUIT', 'MILK'] -> ['BREAD'] \n","   Conf: 1.000    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['BISCUIT', 'BREAD'] -> ['MILK'] \n","   Conf: 0.500    Supp: 0.100    Lift: 2.000 \n","Freq. Itemset: {'BISCUIT', 'MILK', 'BREAD'} \n","   Rule: ['MILK', 'BREAD'] -> ['BISCUIT'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT'] -> ['COCK', 'COFFEE'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['COCK'] -> ['BISCUIT', 'COFFEE'] \n","   Conf: 0.667    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['BISCUIT', 'COCK'] \n","   Conf: 0.250    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COCK'] -> ['COFFEE'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COFFEE'] -> ['COCK'] \n","   Conf: 1.000    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'COFFEE'} \n","   Rule: ['COCK', 'COFFEE'] -> ['BISCUIT'] \n","   Conf: 0.667    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['BISCUIT'] -> ['COCK', 'CORNFLAKES'] \n","   Conf: 0.286    Supp: 0.100    Lift: 2.857 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['COCK'] -> ['BISCUIT', 'CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 4.444 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['CORNFLAKES'] -> ['BISCUIT', 'COCK'] \n","   Conf: 0.333    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['BISCUIT', 'COCK'] -> ['CORNFLAKES'] \n","   Conf: 1.000    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['BISCUIT', 'CORNFLAKES'] -> ['COCK'] \n","   Conf: 0.667    Supp: 0.100    Lift: 4.444 \n","Freq. Itemset: {'BISCUIT', 'COCK', 'CORNFLAKES'} \n","   Rule: ['COCK', 'CORNFLAKES'] -> ['BISCUIT'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.857 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['BISCUIT'] -> ['COFFEE', 'CORNFLAKES'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['CORNFLAKES'] -> ['BISCUIT', 'COFFEE'] \n","   Conf: 0.333    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['BISCUIT', 'CORNFLAKES'] \n","   Conf: 0.250    Supp: 0.100    Lift: 1.667 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['BISCUIT', 'CORNFLAKES'] -> ['COFFEE'] \n","   Conf: 0.667    Supp: 0.100    Lift: 1.667 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COFFEE'] -> ['CORNFLAKES'] \n","   Conf: 1.000    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COFFEE'} \n","   Rule: ['COFFEE', 'CORNFLAKES'] -> ['BISCUIT'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['BISCUIT'] -> ['MAGGI', 'TEA'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['MAGGI'] -> ['BISCUIT', 'TEA'] \n","   Conf: 0.400    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['TEA'] -> ['BISCUIT', 'MAGGI'] \n","   Conf: 0.286    Supp: 0.100    Lift: 2.857 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['BISCUIT', 'MAGGI'] -> ['TEA'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.857 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['BISCUIT', 'TEA'] -> ['MAGGI'] \n","   Conf: 1.000    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'BISCUIT', 'MAGGI', 'TEA'} \n","   Rule: ['MAGGI', 'TEA'] -> ['BISCUIT'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.429 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['TEA'] -> ['BREAD', 'BOURNVITA'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['BREAD'] -> ['TEA', 'BOURNVITA'] \n","   Conf: 0.154    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['BOURNVITA'] -> ['TEA', 'BREAD'] \n","   Conf: 0.500    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['TEA', 'BREAD'] -> ['BOURNVITA'] \n","   Conf: 0.500    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['TEA', 'BOURNVITA'] -> ['BREAD'] \n","   Conf: 1.000    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'TEA', 'BREAD', 'BOURNVITA'} \n","   Rule: ['BREAD', 'BOURNVITA'] -> ['TEA'] \n","   Conf: 0.667    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['SUGER'] -> ['BREAD', 'COFFEE'] \n","   Conf: 0.333    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['BREAD'] -> ['SUGER', 'COFFEE'] \n","   Conf: 0.154    Supp: 0.100    Lift: 0.769 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['SUGER', 'BREAD'] \n","   Conf: 0.250    Supp: 0.100    Lift: 1.250 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['SUGER', 'BREAD'] -> ['COFFEE'] \n","   Conf: 0.500    Supp: 0.100    Lift: 1.250 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['SUGER', 'COFFEE'] -> ['BREAD'] \n","   Conf: 0.500    Supp: 0.100    Lift: 0.769 \n","Freq. Itemset: {'SUGER', 'BREAD', 'COFFEE'} \n","   Rule: ['BREAD', 'COFFEE'] -> ['SUGER'] \n","   Conf: 0.667    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['MAGGI'] -> ['JAM', 'BREAD'] \n","   Conf: 0.400    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['JAM'] -> ['MAGGI', 'BREAD'] \n","   Conf: 1.000    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['BREAD'] -> ['MAGGI', 'JAM'] \n","   Conf: 0.154    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['MAGGI', 'JAM'] -> ['BREAD'] \n","   Conf: 1.000    Supp: 0.100    Lift: 1.538 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['MAGGI', 'BREAD'] -> ['JAM'] \n","   Conf: 0.667    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'MAGGI', 'JAM', 'BREAD'} \n","   Rule: ['JAM', 'BREAD'] -> ['MAGGI'] \n","   Conf: 1.000    Supp: 0.100    Lift: 4.000 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['MAGGI'] -> ['TEA', 'BREAD'] \n","   Conf: 0.400    Supp: 0.100    Lift: 2.000 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['TEA'] -> ['MAGGI', 'BREAD'] \n","   Conf: 0.286    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['BREAD'] -> ['MAGGI', 'TEA'] \n","   Conf: 0.154    Supp: 0.100    Lift: 0.769 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['MAGGI', 'TEA'] -> ['BREAD'] \n","   Conf: 0.500    Supp: 0.100    Lift: 0.769 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['MAGGI', 'BREAD'] -> ['TEA'] \n","   Conf: 0.667    Supp: 0.100    Lift: 1.905 \n","Freq. Itemset: {'MAGGI', 'TEA', 'BREAD'} \n","   Rule: ['TEA', 'BREAD'] -> ['MAGGI'] \n","   Conf: 0.500    Supp: 0.100    Lift: 2.000 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['CORNFLAKES'] -> ['COCK', 'COFFEE'] \n","   Conf: 0.333    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK'] -> ['COFFEE', 'CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['COCK', 'CORNFLAKES'] \n","   Conf: 0.250    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK', 'CORNFLAKES'] -> ['COFFEE'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE', 'CORNFLAKES'] -> ['COCK'] \n","   Conf: 0.500    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK', 'COFFEE'] -> ['CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 2.222 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT'] -> ['COFFEE', 'COCK', 'CORNFLAKES'] \n","   Conf: 0.286    Supp: 0.100    Lift: 2.857 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['CORNFLAKES'] -> ['BISCUIT', 'COCK', 'COFFEE'] \n","   Conf: 0.333    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK'] -> ['COFFEE', 'BISCUIT', 'CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE'] -> ['BISCUIT', 'COCK', 'CORNFLAKES'] \n","   Conf: 0.250    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'CORNFLAKES'] -> ['COCK', 'COFFEE'] \n","   Conf: 0.667    Supp: 0.100    Lift: 4.444 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COCK'] -> ['COFFEE', 'CORNFLAKES'] \n","   Conf: 1.000    Supp: 0.100    Lift: 5.000 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COFFEE'] -> ['COCK', 'CORNFLAKES'] \n","   Conf: 1.000    Supp: 0.100    Lift: 10.000 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK', 'CORNFLAKES'] -> ['BISCUIT', 'COFFEE'] \n","   Conf: 1.000    Supp: 0.100    Lift: 10.000 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE', 'CORNFLAKES'] -> ['BISCUIT', 'COCK'] \n","   Conf: 0.500    Supp: 0.100    Lift: 5.000 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COCK', 'COFFEE'] -> ['BISCUIT', 'CORNFLAKES'] \n","   Conf: 0.667    Supp: 0.100    Lift: 4.444 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COCK', 'CORNFLAKES'] -> ['COFFEE'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.500 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE', 'BISCUIT', 'CORNFLAKES'] -> ['COCK'] \n","   Conf: 1.000    Supp: 0.100    Lift: 6.667 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['BISCUIT', 'COCK', 'COFFEE'] -> ['CORNFLAKES'] \n","   Conf: 1.000    Supp: 0.100    Lift: 3.333 \n","Freq. Itemset: {'BISCUIT', 'CORNFLAKES', 'COCK', 'COFFEE'} \n","   Rule: ['COFFEE', 'COCK', 'CORNFLAKES'] -> ['BISCUIT'] \n","   Conf: 1.000    Supp: 0.100    Lift: 2.857 \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"eVk4zPn1TUqj"},"source":["### (2) FP-Growth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBL5OkZWTdTV"},"outputs":[],"source":["from collections import defaultdict\n","import pandas as pd\n","\n","class HeaderTable:\n","    def __init__(self, itemsets, min_support, frequency=None):\n","        self.__header_table = defaultdict(int)\n","\n","        if frequency is None:\n","            self.frequency = [1 for i in itemsets]\n","        else:\n","            self.frequency = frequency\n","\n","        for index, itemset in enumerate(itemsets):\n","            for item in itemset:\n","                self.__header_table[item] += self.frequency[index]\n","\n","        self.__header_table = dict((item, support) for item, support in self.__header_table.items() if support >= min_support)\n","\n","        if len(self.__header_table) == 0:\n","            self.__header_table = None\n","            return\n","\n","        for item in self.__header_table:\n","            self.__header_table[item] = [self.__header_table[item], None]\n","\n","    def __getitem__(self, key):\n","        return self.__header_table[key]\n","    \n","    def __contains__(self, item):\n","        return item in self.__header_table\n","\n","    def __bool__(self):\n","        return self.__header_table != None\n","    \n","    def items(self):\n","        return self.__header_table.items()\n","    \n","    def update(self, item, target_node):\n","        if self.__header_table[item][1] == None:\n","            self.__header_table[item][1] = target_node\n","        else:\n","            current_node = self.__header_table[item][1]\n","\n","            while current_node.next != None:\n","                current_node = current_node.next\n","            current_node.next = target_node\n","\n","class Node:\n","    def __init__(self, name, frequency, parent_node):\n","        self.name = name\n","        self.count = frequency\n","        self.parent = parent_node\n","        self.children = {}\n","        self.next = None\n","\n","    def increment(self, frequency):\n","        self.count += frequency\n","\n","class FPTree:\n","    def __init__(self, itemsets, header_table, frequency=None):\n","        if frequency is None:\n","            self.frequency = [1 for i in itemsets]\n","        else:\n","            self.frequency = frequency\n","\n","        self.__itemsets = itemsets\n","\n","        self.__header_table = header_table\n","\n","        self.tree = Node('Null', 1, None)\n","    \n","    def construct(self):\n","        if not self.__header_table:\n","            return\n","        \n","        for index, itemset in enumerate(self.__itemsets):\n","            itemset = [item for item in itemset if item in self.__header_table]\n","            itemset.sort(key=lambda item: self.__header_table[item][0], reverse=True)\n","\n","            current_node = self.tree\n","            for item in itemset:\n","                current_node = self.__update(item, current_node, self.frequency[index])\n","    \n","    def __update(self, item, tree_node, frequency):\n","        if item in tree_node.children:\n","            tree_node.children[item].increment(frequency)\n","        else:\n","            new_node = Node(item, frequency, tree_node)\n","            tree_node.children[item] = new_node\n","\n","            self.__header_table.update(item, new_node)\n","        \n","        return tree_node.children[item]\n","\n","class FPGrowth:\n","    def __init__(self, dataset, min_support_ratio):\n","        self.__itemsets = dataset\n","        self.__number_of_itemsets = len(dataset)\n","        self.__min_support = len(dataset) * min_support_ratio\n","        self.__header_table = HeaderTable(dataset, self.__min_support)\n","\n","        fptree = FPTree(dataset, self.__header_table)\n","        fptree.construct()\n","\n","        self.frequent_itemsets = []\n","        self.__results = None\n","        self.__show_item_number = 0\n","        self.__show_name = \"\"\n","\n","    def __ascend_fptree(self, node, prefix_path):\n","        if node.parent != None:\n","            prefix_path.append(node.name)\n","            self.__ascend_fptree(node.parent, prefix_path)\n","    \n","    def __find_prefix_path(self, base_path):\n","        tree_node = self.__header_table[base_path][1] \n","        conditional_paths = []\n","        frequency = []\n","\n","        while tree_node != None:\n","            prefix_path = []\n","\n","            self.__ascend_fptree(tree_node, prefix_path) \n","\n","            if len(prefix_path) > 1:\n","                conditional_paths.append(prefix_path[1:])\n","                frequency.append(tree_node.count)\n","\n","            tree_node = tree_node.next\n","\n","        return conditional_paths, frequency\n","\n","    def mine(self, prefix=set(), header_table=None):\n","        if header_table == None:\n","            header_table = self.__header_table\n","        \n","        sorted_itemsets = [item[0] for item in sorted(list(header_table.items()), key=lambda p:p[1][0])]\n","        \n","        for item in sorted_itemsets:\n","            new_frequent_itemset = prefix.copy()\n","            new_frequent_itemset.add(item)\n","            self.frequent_itemsets.append(new_frequent_itemset)\n","\n","            conditional_pattern_base, frequency = self.__find_prefix_path(item)\n","\n","            new_header_table = HeaderTable(conditional_pattern_base, self.__min_support, frequency)\n","            conditional_fptree = FPTree(conditional_pattern_base, new_header_table, frequency)\n","            conditional_fptree.construct()\n","\n","            if new_header_table:\n","                self.mine(new_frequent_itemset, new_header_table)\n","\n","    def __get_support_count(self, items):\n","        support = 0\n","\n","        if len(items) == 1:\n","            item = items[0]\n","            support = self.__header_table[item][0]\n","        else:\n","            count = 0\n","\n","            for itemset in self.__itemsets:\n","                if set(items).issubset(itemset):\n","                    count += 1\n","            \n","            support = count\n","        \n","        return support\n","\n","    def __to_percentage(self, value):\n","        return \"{:.3%}\".format(value)\n","\n","    def __get_column_order(self, item_number, all_letters, name=\"\"):\n","        a_code = ord(\"A\")\n","\n","        column_order = []\n","\n","        for index in range(item_number):\n","            letter = chr(a_code + index)\n","            column_order.append(f\"{name} {letter}\")\n","\n","        for index in range(item_number):\n","            letter = chr(a_code + index)\n","            column_order.append(f\"support_count({letter})\")\n","            column_order.append(f\"support({letter})\")\n","\n","        for index in range(item_number):\n","            letter = chr(a_code + index)\n","            column_order.append(f\"confidence({letter})\")\n","        \n","        column_order.append(f\"support_count({all_letters})\")\n","        column_order.append(f\"support({all_letters})\")\n","\n","        return column_order\n","    \n","    def __get_results(self, item_number, name=\"\"):\n","        result = {}\n","\n","        a_code = ord(\"A\")\n","        all_letters = \"\"\n","\n","        for i in range(item_number):\n","            letter = chr(a_code + i)\n","            all_letters += letter + (\"\" if i == item_number - 1 else \", \")\n","\n","            result[f\"{name} {letter}\"] = []\n","            result[f\"support({letter})\"] = []\n","            result[f\"support_count({letter})\"] = []\n","            result[f\"confidence({letter})\"] = []\n","        \n","        result[f\"support({all_letters})\"] = []\n","        result[f\"support_count({all_letters})\"] = []\n","        \n","        for itemset in self.frequent_itemsets:\n","            if len(itemset) == 1:\n","                continue\n","            elif len(itemset) <= item_number:\n","                supports = []\n","                for index in range(item_number):\n","                    letter = chr(a_code + index)\n","\n","                    if index < len(itemset):\n","                        item = list(itemset)[index]\n","                        result[f\"{name} {letter}\"].append(item)\n","                        supports.append(self.__get_support_count([item]))\n","                        result[f\"support_count({letter})\"].append(supports[index])\n","                        result[f\"support({letter})\"].append(self.__to_percentage(supports[index] / self.__number_of_itemsets))\n","                    else:\n","                        result[f\"{name} {letter}\"].append(\"\")\n","                        result[f\"support({letter})\"].append(\"\")\n","                        result[f\"support_count({letter})\"].append(\"\")\n","                \n","                support_of_itemset = self.__get_support_count(list(itemset))\n","                result[f\"support_count({all_letters})\"].append(support_of_itemset)\n","                result[f\"support({all_letters})\"].append(self.__to_percentage(support_of_itemset / self.__number_of_itemsets))\n","\n","                confidences = []\n","\n","                for index in range(item_number):\n","                    letter = chr(a_code + index)\n","\n","                    if index < len(itemset):\n","                        support = supports[index]\n","                        confidence = support_of_itemset / support\n","                        result[f\"confidence({letter})\"].append(self.__to_percentage(confidence))\n","                        confidences.append(confidence)\n","                    else:\n","                        result[f\"confidence({letter})\"].append(\"\")\n","\n","\n","        column_order = self.__get_column_order(item_number, all_letters, name)\n","        \n","        self.__results = pd.DataFrame(result).loc[:, column_order]\n","\n","    def show_results(self, item_number=None, name=None):\n","        if self.__results is not None and item_number == None and name == None:\n","            return self.__results \n","        if self.__results is None or item_number != self.__show_item_number or name != self.__show_name:\n","            self.__show_item_number = item_number\n","            self.__show_name = name\n","            self.__get_results(item_number, name)\n","\n","        return self.__results\n","\n","    def export_to_csv(self):\n","        self.__results.to_csv('result.csv')\n","\n","    def __powerset(self, s):\n","      return chain.from_iterable(combinations(s, r) for r in range(1, len(s)))\n","    \n","    def show_association_rule(self, min_confidence):\n","      rules = []\n","      for itemset in self.frequent_itemsets:\n","          subsets = self.__powerset(itemset)\n","          support = self.__get_support_count(list(itemset))\n","          for subset in subsets:\n","              support_of_subset = self.__get_support_count(list(subset))\n","              confidence = float(support / support_of_subset) if support_of_subset > 0 else 0\n","              if(confidence > min_confidence):\n","                  rules.append([set(subset), set(itemset.difference(subset)), confidence])\n","      return rules"]},{"cell_type":"code","source":["fp_growth = FPGrowth(transactions, 0.1)\n","fp_growth.mine()\n","fp_growth.show_results(4, \"Item\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"zFQ4DkS8GJxv","executionInfo":{"status":"ok","timestamp":1667792855560,"user_tz":-480,"elapsed":441,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"outputId":"c095ebc4-b991-4cd5-a889-f033abd87e7f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Item A  Item B  Item C  Item D  support_count(A) support(A)  \\\n","0     MAGGI     JAM                                 5    25.000%   \n","1   BISCUIT   MAGGI     JAM                         7    35.000%   \n","2   BISCUIT   MAGGI     JAM     TEA                 7    35.000%   \n","3   BISCUIT   MAGGI     JAM  COFFEE                 7    35.000%   \n","4   BISCUIT   MAGGI     JAM   BREAD                 7    35.000%   \n","..      ...     ...     ...     ...               ...        ...   \n","73  BISCUIT  COFFEE                                 7    35.000%   \n","74  BISCUIT   BREAD  COFFEE                         7    35.000%   \n","75  BISCUIT   BREAD                                 7    35.000%   \n","76      TEA   BREAD                                 7    35.000%   \n","77    BREAD  COFFEE                                13    65.000%   \n","\n","    support_count(B) support(B) support_count(C) support(C) support_count(D)  \\\n","0                  2    10.000%                                                \n","1                  5    25.000%                2    10.000%                    \n","2                  5    25.000%                2    10.000%                7   \n","3                  5    25.000%                2    10.000%                8   \n","4                  5    25.000%                2    10.000%               13   \n","..               ...        ...              ...        ...              ...   \n","73                 8    40.000%                                                \n","74                13    65.000%                8    40.000%                    \n","75                13    65.000%                                                \n","76                13    65.000%                                                \n","77                 8    40.000%                                                \n","\n","   support(D) confidence(A) confidence(B) confidence(C) confidence(D)  \\\n","0                   40.000%      100.000%                               \n","1                    0.000%        0.000%        0.000%                 \n","2     35.000%        0.000%        0.000%        0.000%        0.000%   \n","3     40.000%        0.000%        0.000%        0.000%        0.000%   \n","4     65.000%        0.000%        0.000%        0.000%        0.000%   \n","..        ...           ...           ...           ...           ...   \n","73                  28.571%       25.000%                               \n","74                   0.000%        0.000%        0.000%                 \n","75                  57.143%       30.769%                               \n","76                  57.143%       30.769%                               \n","77                  23.077%       37.500%                               \n","\n","    support_count(A, B, C, D) support(A, B, C, D)  \n","0                           2             10.000%  \n","1                           0              0.000%  \n","2                           0              0.000%  \n","3                           0              0.000%  \n","4                           0              0.000%  \n","..                        ...                 ...  \n","73                          2             10.000%  \n","74                          0              0.000%  \n","75                          4             20.000%  \n","76                          4             20.000%  \n","77                          3             15.000%  \n","\n","[78 rows x 18 columns]"],"text/html":["\n","  <div id=\"df-4d041141-343b-402a-b75c-5abd10d07244\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Item A</th>\n","      <th>Item B</th>\n","      <th>Item C</th>\n","      <th>Item D</th>\n","      <th>support_count(A)</th>\n","      <th>support(A)</th>\n","      <th>support_count(B)</th>\n","      <th>support(B)</th>\n","      <th>support_count(C)</th>\n","      <th>support(C)</th>\n","      <th>support_count(D)</th>\n","      <th>support(D)</th>\n","      <th>confidence(A)</th>\n","      <th>confidence(B)</th>\n","      <th>confidence(C)</th>\n","      <th>confidence(D)</th>\n","      <th>support_count(A, B, C, D)</th>\n","      <th>support(A, B, C, D)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>MAGGI</td>\n","      <td>JAM</td>\n","      <td></td>\n","      <td></td>\n","      <td>5</td>\n","      <td>25.000%</td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>40.000%</td>\n","      <td>100.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BISCUIT</td>\n","      <td>MAGGI</td>\n","      <td>JAM</td>\n","      <td></td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>5</td>\n","      <td>25.000%</td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>0.000%</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BISCUIT</td>\n","      <td>MAGGI</td>\n","      <td>JAM</td>\n","      <td>TEA</td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>5</td>\n","      <td>25.000%</td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0</td>\n","      <td>0.000%</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BISCUIT</td>\n","      <td>MAGGI</td>\n","      <td>JAM</td>\n","      <td>COFFEE</td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>5</td>\n","      <td>25.000%</td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","      <td>8</td>\n","      <td>40.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0</td>\n","      <td>0.000%</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BISCUIT</td>\n","      <td>MAGGI</td>\n","      <td>JAM</td>\n","      <td>BREAD</td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>5</td>\n","      <td>25.000%</td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","      <td>13</td>\n","      <td>65.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0</td>\n","      <td>0.000%</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>BISCUIT</td>\n","      <td>COFFEE</td>\n","      <td></td>\n","      <td></td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>8</td>\n","      <td>40.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>28.571%</td>\n","      <td>25.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td>2</td>\n","      <td>10.000%</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>BISCUIT</td>\n","      <td>BREAD</td>\n","      <td>COFFEE</td>\n","      <td></td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>13</td>\n","      <td>65.000%</td>\n","      <td>8</td>\n","      <td>40.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td>0.000%</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>0.000%</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>BISCUIT</td>\n","      <td>BREAD</td>\n","      <td></td>\n","      <td></td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>13</td>\n","      <td>65.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>57.143%</td>\n","      <td>30.769%</td>\n","      <td></td>\n","      <td></td>\n","      <td>4</td>\n","      <td>20.000%</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>TEA</td>\n","      <td>BREAD</td>\n","      <td></td>\n","      <td></td>\n","      <td>7</td>\n","      <td>35.000%</td>\n","      <td>13</td>\n","      <td>65.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>57.143%</td>\n","      <td>30.769%</td>\n","      <td></td>\n","      <td></td>\n","      <td>4</td>\n","      <td>20.000%</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>BREAD</td>\n","      <td>COFFEE</td>\n","      <td></td>\n","      <td></td>\n","      <td>13</td>\n","      <td>65.000%</td>\n","      <td>8</td>\n","      <td>40.000%</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>23.077%</td>\n","      <td>37.500%</td>\n","      <td></td>\n","      <td></td>\n","      <td>3</td>\n","      <td>15.000%</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78 rows × 18 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d041141-343b-402a-b75c-5abd10d07244')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4d041141-343b-402a-b75c-5abd10d07244 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4d041141-343b-402a-b75c-5abd10d07244');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# 顯示頻繁項集與關連規則\n","fp_growth.show_association_rule(0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGPG8DiWJ-Zi","executionInfo":{"status":"ok","timestamp":1667792859800,"user_tz":-480,"elapsed":589,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"outputId":"46dd1103-9361-42b9-ccad-5ebd313142cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[{'MAGGI'}, {'JAM'}, 0.4],\n"," [{'JAM'}, {'MAGGI'}, 1.0],\n"," [{'MAGGI'}, {'BREAD', 'JAM'}, 0.4],\n"," [{'JAM'}, {'BREAD', 'MAGGI'}, 1.0],\n"," [{'BREAD'}, {'JAM', 'MAGGI'}, 0.15384615384615385],\n"," [{'JAM', 'MAGGI'}, {'BREAD'}, 1.0],\n"," [{'BREAD', 'MAGGI'}, {'JAM'}, 0.6666666666666666],\n"," [{'BREAD', 'JAM'}, {'MAGGI'}, 1.0],\n"," [{'TEA'}, {'JAM', 'MAGGI'}, 0.14285714285714285],\n"," [{'MAGGI'}, {'JAM', 'TEA'}, 0.2],\n"," [{'JAM'}, {'MAGGI', 'TEA'}, 0.5],\n"," [{'MAGGI', 'TEA'}, {'JAM'}, 0.25],\n"," [{'JAM', 'TEA'}, {'MAGGI'}, 1.0],\n"," [{'JAM', 'MAGGI'}, {'TEA'}, 0.5],\n"," [{'TEA'}, {'BREAD', 'JAM', 'MAGGI'}, 0.14285714285714285],\n"," [{'MAGGI'}, {'BREAD', 'JAM', 'TEA'}, 0.2],\n"," [{'JAM'}, {'BREAD', 'MAGGI', 'TEA'}, 0.5],\n"," [{'MAGGI', 'TEA'}, {'BREAD', 'JAM'}, 0.25],\n"," [{'JAM', 'TEA'}, {'BREAD', 'MAGGI'}, 1.0],\n"," [{'BREAD', 'TEA'}, {'JAM', 'MAGGI'}, 0.25],\n"," [{'JAM', 'MAGGI'}, {'BREAD', 'TEA'}, 0.5],\n"," [{'BREAD', 'MAGGI'}, {'JAM', 'TEA'}, 0.3333333333333333],\n"," [{'BREAD', 'JAM'}, {'MAGGI', 'TEA'}, 0.5],\n"," [{'JAM', 'MAGGI', 'TEA'}, {'BREAD'}, 1.0],\n"," [{'BREAD', 'MAGGI', 'TEA'}, {'JAM'}, 0.5],\n"," [{'BREAD', 'JAM', 'TEA'}, {'MAGGI'}, 1.0],\n"," [{'BREAD', 'JAM', 'MAGGI'}, {'TEA'}, 0.5],\n"," [{'JAM'}, {'BREAD'}, 1.0],\n"," [{'BREAD'}, {'JAM'}, 0.15384615384615385],\n"," [{'COCK'}, {'CORNFLAKES'}, 0.6666666666666666],\n"," [{'CORNFLAKES'}, {'COCK'}, 0.3333333333333333],\n"," [{'BISCUIT'}, {'COCK', 'CORNFLAKES'}, 0.2857142857142857],\n"," [{'COCK'}, {'BISCUIT', 'CORNFLAKES'}, 0.6666666666666666],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'COCK'}, 0.3333333333333333],\n"," [{'BISCUIT', 'COCK'}, {'CORNFLAKES'}, 1.0],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'COCK'}, 0.6666666666666666],\n"," [{'COCK', 'CORNFLAKES'}, {'BISCUIT'}, 1.0],\n"," [{'COFFEE'}, {'BISCUIT', 'COCK', 'CORNFLAKES'}, 0.25],\n"," [{'BISCUIT'}, {'COCK', 'COFFEE', 'CORNFLAKES'}, 0.2857142857142857],\n"," [{'COCK'}, {'BISCUIT', 'COFFEE', 'CORNFLAKES'}, 0.6666666666666666],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'COCK', 'COFFEE'}, 0.3333333333333333],\n"," [{'BISCUIT', 'COFFEE'}, {'COCK', 'CORNFLAKES'}, 1.0],\n"," [{'COCK', 'COFFEE'}, {'BISCUIT', 'CORNFLAKES'}, 0.6666666666666666],\n"," [{'COFFEE', 'CORNFLAKES'}, {'BISCUIT', 'COCK'}, 0.5],\n"," [{'BISCUIT', 'COCK'}, {'COFFEE', 'CORNFLAKES'}, 1.0],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'COCK', 'COFFEE'}, 0.6666666666666666],\n"," [{'COCK', 'CORNFLAKES'}, {'BISCUIT', 'COFFEE'}, 1.0],\n"," [{'BISCUIT', 'COCK', 'COFFEE'}, {'CORNFLAKES'}, 1.0],\n"," [{'BISCUIT', 'COFFEE', 'CORNFLAKES'}, {'COCK'}, 1.0],\n"," [{'COCK', 'COFFEE', 'CORNFLAKES'}, {'BISCUIT'}, 1.0],\n"," [{'BISCUIT', 'COCK', 'CORNFLAKES'}, {'COFFEE'}, 1.0],\n"," [{'COFFEE'}, {'COCK', 'CORNFLAKES'}, 0.25],\n"," [{'COCK'}, {'COFFEE', 'CORNFLAKES'}, 0.6666666666666666],\n"," [{'CORNFLAKES'}, {'COCK', 'COFFEE'}, 0.3333333333333333],\n"," [{'COCK', 'COFFEE'}, {'CORNFLAKES'}, 0.6666666666666666],\n"," [{'COFFEE', 'CORNFLAKES'}, {'COCK'}, 0.5],\n"," [{'COCK', 'CORNFLAKES'}, {'COFFEE'}, 1.0],\n"," [{'BISCUIT'}, {'COCK'}, 0.2857142857142857],\n"," [{'COCK'}, {'BISCUIT'}, 0.6666666666666666],\n"," [{'BISCUIT'}, {'COCK', 'COFFEE'}, 0.2857142857142857],\n"," [{'COCK'}, {'BISCUIT', 'COFFEE'}, 0.6666666666666666],\n"," [{'COFFEE'}, {'BISCUIT', 'COCK'}, 0.25],\n"," [{'BISCUIT', 'COCK'}, {'COFFEE'}, 1.0],\n"," [{'BISCUIT', 'COFFEE'}, {'COCK'}, 1.0],\n"," [{'COCK', 'COFFEE'}, {'BISCUIT'}, 0.6666666666666666],\n"," [{'COCK'}, {'COFFEE'}, 1.0],\n"," [{'COFFEE'}, {'COCK'}, 0.375],\n"," [{'COCK'}, {'BREAD', 'COFFEE'}, 0.3333333333333333],\n"," [{'COFFEE'}, {'BREAD', 'COCK'}, 0.125],\n"," [{'BREAD', 'COCK'}, {'COFFEE'}, 1.0],\n"," [{'COCK', 'COFFEE'}, {'BREAD'}, 0.3333333333333333],\n"," [{'BREAD', 'COFFEE'}, {'COCK'}, 0.3333333333333333],\n"," [{'TEA'}, {'BOURNVITA'}, 0.2857142857142857],\n"," [{'BOURNVITA'}, {'TEA'}, 0.5],\n"," [{'TEA'}, {'BOURNVITA', 'BREAD'}, 0.2857142857142857],\n"," [{'BREAD'}, {'BOURNVITA', 'TEA'}, 0.15384615384615385],\n"," [{'BOURNVITA'}, {'BREAD', 'TEA'}, 0.5],\n"," [{'BREAD', 'TEA'}, {'BOURNVITA'}, 0.5],\n"," [{'BOURNVITA', 'TEA'}, {'BREAD'}, 1.0],\n"," [{'BOURNVITA', 'BREAD'}, {'TEA'}, 0.6666666666666666],\n"," [{'SUGER'}, {'BOURNVITA'}, 0.3333333333333333],\n"," [{'BOURNVITA'}, {'SUGER'}, 0.5],\n"," [{'COFFEE'}, {'BOURNVITA', 'SUGER'}, 0.125],\n"," [{'SUGER'}, {'BOURNVITA', 'COFFEE'}, 0.16666666666666666],\n"," [{'BOURNVITA'}, {'COFFEE', 'SUGER'}, 0.25],\n"," [{'COFFEE', 'SUGER'}, {'BOURNVITA'}, 0.25],\n"," [{'BOURNVITA', 'COFFEE'}, {'SUGER'}, 1.0],\n"," [{'BOURNVITA', 'SUGER'}, {'COFFEE'}, 0.5],\n"," [{'SUGER'}, {'BOURNVITA', 'BREAD'}, 0.16666666666666666],\n"," [{'BOURNVITA'}, {'BREAD', 'SUGER'}, 0.25],\n"," [{'BREAD', 'SUGER'}, {'BOURNVITA'}, 0.25],\n"," [{'BOURNVITA', 'SUGER'}, {'BREAD'}, 0.5],\n"," [{'BOURNVITA', 'BREAD'}, {'SUGER'}, 0.3333333333333333],\n"," [{'BREAD'}, {'BOURNVITA'}, 0.23076923076923078],\n"," [{'BOURNVITA'}, {'BREAD'}, 0.75],\n"," [{'MILK'}, {'BISCUIT'}, 0.4],\n"," [{'BISCUIT'}, {'MILK'}, 0.2857142857142857],\n"," [{'MILK'}, {'BISCUIT', 'BREAD'}, 0.4],\n"," [{'BREAD'}, {'BISCUIT', 'MILK'}, 0.15384615384615385],\n"," [{'BISCUIT'}, {'BREAD', 'MILK'}, 0.2857142857142857],\n"," [{'BREAD', 'MILK'}, {'BISCUIT'}, 0.5],\n"," [{'BISCUIT', 'MILK'}, {'BREAD'}, 1.0],\n"," [{'BISCUIT', 'BREAD'}, {'MILK'}, 0.5],\n"," [{'MILK'}, {'CORNFLAKES'}, 0.4],\n"," [{'CORNFLAKES'}, {'MILK'}, 0.3333333333333333],\n"," [{'MILK'}, {'CORNFLAKES', 'TEA'}, 0.2],\n"," [{'TEA'}, {'CORNFLAKES', 'MILK'}, 0.14285714285714285],\n"," [{'CORNFLAKES'}, {'MILK', 'TEA'}, 0.16666666666666666],\n"," [{'MILK', 'TEA'}, {'CORNFLAKES'}, 1.0],\n"," [{'CORNFLAKES', 'MILK'}, {'TEA'}, 0.5],\n"," [{'CORNFLAKES', 'TEA'}, {'MILK'}, 0.5],\n"," [{'MILK'}, {'BISCUIT', 'CORNFLAKES'}, 0.2],\n"," [{'BISCUIT'}, {'CORNFLAKES', 'MILK'}, 0.14285714285714285],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'MILK'}, 0.16666666666666666],\n"," [{'BISCUIT', 'MILK'}, {'CORNFLAKES'}, 0.5],\n"," [{'CORNFLAKES', 'MILK'}, {'BISCUIT'}, 0.5],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'MILK'}, 0.3333333333333333],\n"," [{'MILK'}, {'BISCUIT', 'BREAD', 'CORNFLAKES'}, 0.2],\n"," [{'BISCUIT'}, {'BREAD', 'CORNFLAKES', 'MILK'}, 0.14285714285714285],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'BREAD', 'MILK'}, 0.16666666666666666],\n"," [{'BREAD', 'MILK'}, {'BISCUIT', 'CORNFLAKES'}, 0.25],\n"," [{'BISCUIT', 'MILK'}, {'BREAD', 'CORNFLAKES'}, 0.5],\n"," [{'CORNFLAKES', 'MILK'}, {'BISCUIT', 'BREAD'}, 0.5],\n"," [{'BISCUIT', 'BREAD'}, {'CORNFLAKES', 'MILK'}, 0.25],\n"," [{'BREAD', 'CORNFLAKES'}, {'BISCUIT', 'MILK'}, 1.0],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'BREAD', 'MILK'}, 0.3333333333333333],\n"," [{'BISCUIT', 'BREAD', 'MILK'}, {'CORNFLAKES'}, 0.5],\n"," [{'BREAD', 'CORNFLAKES', 'MILK'}, {'BISCUIT'}, 1.0],\n"," [{'BISCUIT', 'CORNFLAKES', 'MILK'}, {'BREAD'}, 1.0],\n"," [{'BISCUIT', 'BREAD', 'CORNFLAKES'}, {'MILK'}, 1.0],\n"," [{'COFFEE'}, {'CORNFLAKES', 'MILK'}, 0.125],\n"," [{'MILK'}, {'COFFEE', 'CORNFLAKES'}, 0.2],\n"," [{'CORNFLAKES'}, {'COFFEE', 'MILK'}, 0.16666666666666666],\n"," [{'COFFEE', 'MILK'}, {'CORNFLAKES'}, 1.0],\n"," [{'COFFEE', 'CORNFLAKES'}, {'MILK'}, 0.25],\n"," [{'CORNFLAKES', 'MILK'}, {'COFFEE'}, 0.5],\n"," [{'MILK'}, {'BREAD'}, 0.8],\n"," [{'BREAD'}, {'MILK'}, 0.3076923076923077],\n"," [{'BISCUIT'}, {'MAGGI'}, 0.2857142857142857],\n"," [{'MAGGI'}, {'BISCUIT'}, 0.4],\n"," [{'BISCUIT'}, {'MAGGI', 'TEA'}, 0.2857142857142857],\n"," [{'MAGGI'}, {'BISCUIT', 'TEA'}, 0.4],\n"," [{'TEA'}, {'BISCUIT', 'MAGGI'}, 0.2857142857142857],\n"," [{'BISCUIT', 'MAGGI'}, {'TEA'}, 1.0],\n"," [{'BISCUIT', 'TEA'}, {'MAGGI'}, 1.0],\n"," [{'MAGGI', 'TEA'}, {'BISCUIT'}, 0.5],\n"," [{'BISCUIT'}, {'BREAD', 'MAGGI', 'TEA'}, 0.14285714285714285],\n"," [{'MAGGI'}, {'BISCUIT', 'BREAD', 'TEA'}, 0.2],\n"," [{'TEA'}, {'BISCUIT', 'BREAD', 'MAGGI'}, 0.14285714285714285],\n"," [{'BISCUIT', 'MAGGI'}, {'BREAD', 'TEA'}, 0.5],\n"," [{'BISCUIT', 'TEA'}, {'BREAD', 'MAGGI'}, 0.5],\n"," [{'BISCUIT', 'BREAD'}, {'MAGGI', 'TEA'}, 0.25],\n"," [{'MAGGI', 'TEA'}, {'BISCUIT', 'BREAD'}, 0.25],\n"," [{'BREAD', 'MAGGI'}, {'BISCUIT', 'TEA'}, 0.3333333333333333],\n"," [{'BREAD', 'TEA'}, {'BISCUIT', 'MAGGI'}, 0.25],\n"," [{'BISCUIT', 'MAGGI', 'TEA'}, {'BREAD'}, 0.5],\n"," [{'BISCUIT', 'BREAD', 'MAGGI'}, {'TEA'}, 1.0],\n"," [{'BISCUIT', 'BREAD', 'TEA'}, {'MAGGI'}, 1.0],\n"," [{'BREAD', 'MAGGI', 'TEA'}, {'BISCUIT'}, 0.5],\n"," [{'BISCUIT'}, {'BREAD', 'MAGGI'}, 0.14285714285714285],\n"," [{'MAGGI'}, {'BISCUIT', 'BREAD'}, 0.2],\n"," [{'BISCUIT', 'MAGGI'}, {'BREAD'}, 0.5],\n"," [{'BISCUIT', 'BREAD'}, {'MAGGI'}, 0.25],\n"," [{'BREAD', 'MAGGI'}, {'BISCUIT'}, 0.3333333333333333],\n"," [{'MAGGI'}, {'BREAD'}, 0.6],\n"," [{'BREAD'}, {'MAGGI'}, 0.23076923076923078],\n"," [{'MAGGI'}, {'TEA'}, 0.8],\n"," [{'TEA'}, {'MAGGI'}, 0.5714285714285714],\n"," [{'MAGGI'}, {'BREAD', 'TEA'}, 0.4],\n"," [{'TEA'}, {'BREAD', 'MAGGI'}, 0.2857142857142857],\n"," [{'BREAD'}, {'MAGGI', 'TEA'}, 0.15384615384615385],\n"," [{'MAGGI', 'TEA'}, {'BREAD'}, 0.5],\n"," [{'BREAD', 'MAGGI'}, {'TEA'}, 0.6666666666666666],\n"," [{'BREAD', 'TEA'}, {'MAGGI'}, 0.5],\n"," [{'TEA'}, {'CORNFLAKES'}, 0.2857142857142857],\n"," [{'CORNFLAKES'}, {'TEA'}, 0.3333333333333333],\n"," [{'BISCUIT'}, {'CORNFLAKES'}, 0.42857142857142855],\n"," [{'CORNFLAKES'}, {'BISCUIT'}, 0.5],\n"," [{'COFFEE'}, {'BISCUIT', 'CORNFLAKES'}, 0.25],\n"," [{'BISCUIT'}, {'COFFEE', 'CORNFLAKES'}, 0.2857142857142857],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'COFFEE'}, 0.3333333333333333],\n"," [{'BISCUIT', 'COFFEE'}, {'CORNFLAKES'}, 1.0],\n"," [{'COFFEE', 'CORNFLAKES'}, {'BISCUIT'}, 0.5],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'COFFEE'}, 0.6666666666666666],\n"," [{'BISCUIT'}, {'BREAD', 'CORNFLAKES'}, 0.14285714285714285],\n"," [{'CORNFLAKES'}, {'BISCUIT', 'BREAD'}, 0.16666666666666666],\n"," [{'BISCUIT', 'BREAD'}, {'CORNFLAKES'}, 0.25],\n"," [{'BISCUIT', 'CORNFLAKES'}, {'BREAD'}, 0.3333333333333333],\n"," [{'BREAD', 'CORNFLAKES'}, {'BISCUIT'}, 1.0],\n"," [{'COFFEE'}, {'CORNFLAKES'}, 0.5],\n"," [{'CORNFLAKES'}, {'COFFEE'}, 0.6666666666666666],\n"," [{'SUGER'}, {'COFFEE'}, 0.6666666666666666],\n"," [{'COFFEE'}, {'SUGER'}, 0.5],\n"," [{'SUGER'}, {'BREAD', 'COFFEE'}, 0.3333333333333333],\n"," [{'BREAD'}, {'COFFEE', 'SUGER'}, 0.15384615384615385],\n"," [{'COFFEE'}, {'BREAD', 'SUGER'}, 0.25],\n"," [{'BREAD', 'SUGER'}, {'COFFEE'}, 0.5],\n"," [{'COFFEE', 'SUGER'}, {'BREAD'}, 0.5],\n"," [{'BREAD', 'COFFEE'}, {'SUGER'}, 0.6666666666666666],\n"," [{'SUGER'}, {'BREAD'}, 0.6666666666666666],\n"," [{'BREAD'}, {'SUGER'}, 0.3076923076923077],\n"," [{'BISCUIT'}, {'TEA'}, 0.2857142857142857],\n"," [{'TEA'}, {'BISCUIT'}, 0.2857142857142857],\n"," [{'BISCUIT'}, {'BREAD', 'TEA'}, 0.14285714285714285],\n"," [{'TEA'}, {'BISCUIT', 'BREAD'}, 0.14285714285714285],\n"," [{'BISCUIT', 'TEA'}, {'BREAD'}, 0.5],\n"," [{'BISCUIT', 'BREAD'}, {'TEA'}, 0.25],\n"," [{'BREAD', 'TEA'}, {'BISCUIT'}, 0.25],\n"," [{'BISCUIT'}, {'COFFEE'}, 0.2857142857142857],\n"," [{'COFFEE'}, {'BISCUIT'}, 0.25],\n"," [{'BISCUIT'}, {'BREAD'}, 0.5714285714285714],\n"," [{'BREAD'}, {'BISCUIT'}, 0.3076923076923077],\n"," [{'TEA'}, {'BREAD'}, 0.5714285714285714],\n"," [{'BREAD'}, {'TEA'}, 0.3076923076923077],\n"," [{'BREAD'}, {'COFFEE'}, 0.23076923076923078],\n"," [{'COFFEE'}, {'BREAD'}, 0.375]]"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"GPNE7x2dTkAV"},"source":["### (3) Write a report to analyze the situations (e.g., data size, data distribution, minimal support threshold setting, and pattern density) where one algorithm may perform better than the others, and state why."]},{"cell_type":"markdown","metadata":{"id":"y9f9B-01Tqk6"},"source":["Apriori:\n","1. Apriori 採用逐層搜索的迭代方法，做法簡單，沒有復雜的理論推導，實作的難度比較低。\n","2. 當資料集較大時，要多次掃描資料集，因此速度會比較慢。\n","3. FP-Growth 會需要使用較多的記憶體空間，所以若不想使用那麼多記憶體空間可以使用 Apriori\n","\n","FP-Growth:\n","1.\t由於 FP-Growth 不需要建立候選集，因此它可以比 Apriori 算法快。\n","2.\t當資料集過大時，由於樹的節點過多，會使用大量記憶體空間。但可以將資料集分割，使用多台電腦並行處理。\n","3.\t當資料集較小時，由於不用像 Apriori 一樣需要多次掃描資料集，最多只需要掃描兩次就好了。因此速度較快，效率較高。\n","4. 隨著最小支持度的增加，兩種算法的速度都有加快，且兩者的性能差距也越來越小。因為 Apriori 能夠在每一步刪除大部分候選集並快速收斂。所以，如果想要速度更快，只要加大最小支持度就好。\n","5. 隨著資料量的增加，Apriori 和 FP-Growth 所需時間都會增加。但是 Apriori 比 FP-Growth 花費的時間更多。"]},{"cell_type":"markdown","metadata":{"id":"VFL2EYZCTrlr"},"source":["## 6.15 The DBLP data set (www.informatik.uni-trier.de/~ley/db/) consists of over one million entries of research papers published in computer science conferences and journals. Among these entries, there are a good number of authors that have coauthor relationships."]},{"cell_type":"markdown","metadata":{"id":"7W2xzxLWT4nb"},"source":["### (a) Propose a method to efficiently mine a set of coauthor relationships that are closely correlated (e.g. often coauthoring papers together)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104487,"status":"ok","timestamp":1667793074885,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"},"user_tz":-480},"id":"COxzEIMh2qM9","outputId":"74c28fc3-d148-4ae8-8102-59f9a4f9ff34"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-07 03:49:30--  https://dblp.org/xml/dblp.dtd\n","Resolving dblp.org (dblp.org)... 192.76.146.204\n","Connecting to dblp.org (dblp.org)|192.76.146.204|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12622 (12K) [application/xml-dtd]\n","Saving to: ‘dblp.dtd’\n","\n","dblp.dtd            100%[===================>]  12.33K  --.-KB/s    in 0s      \n","\n","2022-11-07 03:49:32 (97.5 MB/s) - ‘dblp.dtd’ saved [12622/12622]\n","\n","--2022-11-07 03:49:32--  https://dblp.org/xml/dblp.xml.gz\n","Resolving dblp.org (dblp.org)... 192.76.146.204\n","Connecting to dblp.org (dblp.org)|192.76.146.204|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 739940153 (706M) [application/x-gzip]\n","Saving to: ‘dblp.xml.gz’\n","\n","dblp.xml.gz         100%[===================>] 705.66M  10.5MB/s    in 62s     \n","\n","2022-11-07 03:50:35 (11.4 MB/s) - ‘dblp.xml.gz’ saved [739940153/739940153]\n","\n"]}],"source":["# 下載 DBLP 資料集\n","!wget https://dblp.org/xml/dblp.dtd\n","!wget https://dblp.org/xml/dblp.xml.gz\n","!gzip -d dblp.xml.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGbTviG9XD5J"},"outputs":[],"source":["\"\"\"\n","讀取 XML 並將每筆資料的作者提取出來存到 authors.txt\n","約需 3 分鐘\n","\"\"\"\n","\n","import codecs\n","from lxml import etree\n","\n","class DBLPLoader:\n","  def __init__(self, source_path):\n","    self.context = etree.iterparse(source=source_path, dtd_validation=True, load_dtd=True)\n","    self.current_tag = \"\"\n","  \n","  def clear_element(self, element):\n","    element.clear()\n","\n","    while element.getprevious() is not None:\n","      del element.getparent()[0]\n","\n","  def extract_authors(self, element):\n","    return \",\".join(author.text for author in element.findall(\"author\"))\n","\n","  def parse(self, output_file):\n","    for _, element in self.context:\n","      if element.tag == \"article\":\n","        authors = self.extract_authors(element)\n","        output_file.write(f\"{authors}\\n\")\n","      \n","        self.clear_element(element)\n","\n","dblp_loader = DBLPLoader(\"dblp.xml\")\n","output_file = codecs.open(\"authors.txt\", \"w\", \"utf-8\")\n","dblp_loader.parse(output_file)\n","output_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-A89KEPikYdP"},"outputs":[],"source":["\"\"\"\n","讀取 authors.txt\n","並將每篇論文的作者變成一個 itemset 存到 dataset 這個二維陣列\n","\"\"\"\n","\n","dataset = []\n","\n","with open(\"authors.txt\", \"r\") as file:\n","  for line in file.readlines():\n","    authors = line.strip().split(\",\")\n","    if len(authors) > 0:\n","      dataset.append(list(set(authors)))"]},{"cell_type":"code","source":["\"\"\"\n","用 FP Growth 找出經常合作寫論文的教授集合\n","並且顯示結果和輸出成 csv\n","\n","confidence(A) 表示出現 A 教授的情況下出現 B 教授和 C 教授的信心水準\n","confidence(B) 表示出現 B 教授的情況下出現 A 教授和 C 教授的信心水準\n","confidence(C) 表示出現 C 教授的情況下出現 A 教授和 B 教授的信心水準\n","\"\"\"\n","\n","fp_growth = FPGrowth(dataset, 0.00004)\n","fp_growth.mine()\n","fp_growth.show_results(3, \"Author\")"],"metadata":{"id":"3ntnr1wKMwye","executionInfo":{"status":"ok","timestamp":1667793451794,"user_tz":-480,"elapsed":106104,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"b77a1c8e-833e-4f71-92df-f8cfb57752a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Author A              Author B Author C  support_count(A)  \\\n","0   Juan R. Torregrosa        Alicia Cordero                        138   \n","1    A. A. Zaidan 0001          B. B. Zaidan                        125   \n","2       Liang Gao 0001         Xinyu Li 0001                        251   \n","3     Yongming Li 0002        Shaocheng Tong                        135   \n","4     Richa Singh 0001          Mayank Vatsa                        138   \n","..                 ...                   ...      ...               ...   \n","58          Walid Saad          Mehdi Bennis                        519   \n","59      Mohsen Guizani          Xiaojiang Du                        893   \n","60      Robert Schober  Derrick Wing Kwan Ng                        721   \n","61        Dusit Niyato          Zhu Han 0001                        710   \n","62         Dacheng Tao       Xuelong Li 0001                       1024   \n","\n","   support(A)  support_count(B) support(B) support_count(C) support(C)  \\\n","0      0.005%               121     0.004%                               \n","1      0.004%               123     0.004%                               \n","2      0.008%               131     0.004%                               \n","3      0.005%               299     0.010%                               \n","4      0.005%               135     0.005%                               \n","..        ...               ...        ...              ...        ...   \n","58     0.017%               417     0.014%                               \n","59     0.030%               427     0.014%                               \n","60     0.024%               447     0.015%                               \n","61     0.024%               965     0.032%                               \n","62     0.034%               828     0.028%                               \n","\n","   confidence(A) confidence(B) confidence(C)  support_count(A, B, C)  \\\n","0        86.957%       99.174%                                   120   \n","1        96.000%       97.561%                                   120   \n","2        50.199%       96.183%                                   126   \n","3        91.111%       41.137%                                   123   \n","4        96.377%       98.519%                                   133   \n","..           ...           ...           ...                     ...   \n","58       24.277%       30.216%                                   126   \n","59       27.884%       58.314%                                   249   \n","60       20.250%       32.662%                                   146   \n","61       17.606%       12.953%                                   125   \n","62       13.965%       17.271%                                   143   \n","\n","   support(A, B, C)  \n","0            0.004%  \n","1            0.004%  \n","2            0.004%  \n","3            0.004%  \n","4            0.004%  \n","..              ...  \n","58           0.004%  \n","59           0.008%  \n","60           0.005%  \n","61           0.004%  \n","62           0.005%  \n","\n","[63 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-8d7a32a9-1d99-46dd-82f9-bc3e5bb658ab\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Author A</th>\n","      <th>Author B</th>\n","      <th>Author C</th>\n","      <th>support_count(A)</th>\n","      <th>support(A)</th>\n","      <th>support_count(B)</th>\n","      <th>support(B)</th>\n","      <th>support_count(C)</th>\n","      <th>support(C)</th>\n","      <th>confidence(A)</th>\n","      <th>confidence(B)</th>\n","      <th>confidence(C)</th>\n","      <th>support_count(A, B, C)</th>\n","      <th>support(A, B, C)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Juan R. Torregrosa</td>\n","      <td>Alicia Cordero</td>\n","      <td></td>\n","      <td>138</td>\n","      <td>0.005%</td>\n","      <td>121</td>\n","      <td>0.004%</td>\n","      <td></td>\n","      <td></td>\n","      <td>86.957%</td>\n","      <td>99.174%</td>\n","      <td></td>\n","      <td>120</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A. A. Zaidan 0001</td>\n","      <td>B. B. Zaidan</td>\n","      <td></td>\n","      <td>125</td>\n","      <td>0.004%</td>\n","      <td>123</td>\n","      <td>0.004%</td>\n","      <td></td>\n","      <td></td>\n","      <td>96.000%</td>\n","      <td>97.561%</td>\n","      <td></td>\n","      <td>120</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Liang Gao 0001</td>\n","      <td>Xinyu Li 0001</td>\n","      <td></td>\n","      <td>251</td>\n","      <td>0.008%</td>\n","      <td>131</td>\n","      <td>0.004%</td>\n","      <td></td>\n","      <td></td>\n","      <td>50.199%</td>\n","      <td>96.183%</td>\n","      <td></td>\n","      <td>126</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Yongming Li 0002</td>\n","      <td>Shaocheng Tong</td>\n","      <td></td>\n","      <td>135</td>\n","      <td>0.005%</td>\n","      <td>299</td>\n","      <td>0.010%</td>\n","      <td></td>\n","      <td></td>\n","      <td>91.111%</td>\n","      <td>41.137%</td>\n","      <td></td>\n","      <td>123</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Richa Singh 0001</td>\n","      <td>Mayank Vatsa</td>\n","      <td></td>\n","      <td>138</td>\n","      <td>0.005%</td>\n","      <td>135</td>\n","      <td>0.005%</td>\n","      <td></td>\n","      <td></td>\n","      <td>96.377%</td>\n","      <td>98.519%</td>\n","      <td></td>\n","      <td>133</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>Walid Saad</td>\n","      <td>Mehdi Bennis</td>\n","      <td></td>\n","      <td>519</td>\n","      <td>0.017%</td>\n","      <td>417</td>\n","      <td>0.014%</td>\n","      <td></td>\n","      <td></td>\n","      <td>24.277%</td>\n","      <td>30.216%</td>\n","      <td></td>\n","      <td>126</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>Mohsen Guizani</td>\n","      <td>Xiaojiang Du</td>\n","      <td></td>\n","      <td>893</td>\n","      <td>0.030%</td>\n","      <td>427</td>\n","      <td>0.014%</td>\n","      <td></td>\n","      <td></td>\n","      <td>27.884%</td>\n","      <td>58.314%</td>\n","      <td></td>\n","      <td>249</td>\n","      <td>0.008%</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>Robert Schober</td>\n","      <td>Derrick Wing Kwan Ng</td>\n","      <td></td>\n","      <td>721</td>\n","      <td>0.024%</td>\n","      <td>447</td>\n","      <td>0.015%</td>\n","      <td></td>\n","      <td></td>\n","      <td>20.250%</td>\n","      <td>32.662%</td>\n","      <td></td>\n","      <td>146</td>\n","      <td>0.005%</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>Dusit Niyato</td>\n","      <td>Zhu Han 0001</td>\n","      <td></td>\n","      <td>710</td>\n","      <td>0.024%</td>\n","      <td>965</td>\n","      <td>0.032%</td>\n","      <td></td>\n","      <td></td>\n","      <td>17.606%</td>\n","      <td>12.953%</td>\n","      <td></td>\n","      <td>125</td>\n","      <td>0.004%</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>Dacheng Tao</td>\n","      <td>Xuelong Li 0001</td>\n","      <td></td>\n","      <td>1024</td>\n","      <td>0.034%</td>\n","      <td>828</td>\n","      <td>0.028%</td>\n","      <td></td>\n","      <td></td>\n","      <td>13.965%</td>\n","      <td>17.271%</td>\n","      <td></td>\n","      <td>143</td>\n","      <td>0.005%</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>63 rows × 14 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d7a32a9-1d99-46dd-82f9-bc3e5bb658ab')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d7a32a9-1d99-46dd-82f9-bc3e5bb658ab button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d7a32a9-1d99-46dd-82f9-bc3e5bb658ab');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# 將結果匯出成 csv\n","fp_growth.export_to_csv()"],"metadata":{"id":"Up1RsM5X6ynq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GB9Wb_pgUDqB"},"source":["### (b) Based on the mining results and the pattern evaluation measures discussed in this chapter, discuss which measure may convincingly uncover close collaboration patterns better than others"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9xKC1nrUH6P","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1667793469096,"user_tz":-480,"elapsed":3838,"user":{"displayName":"北科大-陳彥宇","userId":"06870126838357103207"}},"outputId":"a7abe2ec-d24d-4afe-968f-c17815ab1171"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Author A     Author B  support_count(A)  aupport_count(B)        Lift  \\\n","0  Soon Xin Ng  Lajos Hanzo               167              1175  2293.00981   \n","\n","            X^2  all confidence  max confidence    cosine   jaccard  \\\n","0  6.153275e+10         0.12766        0.898204  0.338621  0.125839   \n","\n","   kulczynski  \n","0    0.512932  "],"text/html":["\n","  <div id=\"df-ef707b6a-9d47-4e48-b3d6-bdef569e9e0e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Author A</th>\n","      <th>Author B</th>\n","      <th>support_count(A)</th>\n","      <th>aupport_count(B)</th>\n","      <th>Lift</th>\n","      <th>X^2</th>\n","      <th>all confidence</th>\n","      <th>max confidence</th>\n","      <th>cosine</th>\n","      <th>jaccard</th>\n","      <th>kulczynski</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Soon Xin Ng</td>\n","      <td>Lajos Hanzo</td>\n","      <td>167</td>\n","      <td>1175</td>\n","      <td>2293.00981</td>\n","      <td>6.153275e+10</td>\n","      <td>0.12766</td>\n","      <td>0.898204</td>\n","      <td>0.338621</td>\n","      <td>0.125839</td>\n","      <td>0.512932</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef707b6a-9d47-4e48-b3d6-bdef569e9e0e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ef707b6a-9d47-4e48-b3d6-bdef569e9e0e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ef707b6a-9d47-4e48-b3d6-bdef569e9e0e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":66}],"source":["class PatternEvaluation:\n","  def __init__(self, dataset):\n","    self.__itemsets = dataset\n","\n","  def __count_coauthor(self, coauthor):\n","    result = 0\n","    coauthor_set = set(coauthor)\n","\n","    for itemset in self.__itemsets:\n","      if coauthor_set.issubset(itemset):\n","        result += 1\n","    \n","    return result\n","\n","  def __count(self, a, is_contain=True):\n","    result = 0\n","\n","    for itemset in self.__itemsets:\n","      if a in itemset and is_contain:\n","        result += 1\n","      elif a not in itemset and not is_contain:\n","        result += 1\n","\n","    return result\n","\n","  def __lift(self, a, b, ab):\n","    return ab / (a * b)\n","\n","  def __chi_square_test(self, a, b, not_a, not_b):\n","    total = a + b + not_a + not_b\n","\n","    expected_a = (a + b) / total * a\n","    expected_not_a = (not_a + not_b) / total * a\n","    expected_b = (a + b) / total * b\n","    expected_not_b = (not_a + not_b) / total * b\n","\n","    return (a - expected_a) ** 2 / expected_a + \\\n","           (not_a - expected_not_a) ** 2 / expected_not_a + \\\n","           (b - expected_b) ** 2 / expected_b + \\\n","           (not_b - expected_not_b) ** 2 / expected_not_b\n","\n","  def __all_confidence(self, a, b, ab):\n","    return ab / max(a, b)\n","\n","  def __max_confidence(self, a, b, ab):\n","    return max(ab / a, ab / b)\n","  \n","  def __cosine(self, a, b, ab):\n","    return ab / ((a * b) ** 0.5)\n","\n","  def __jaccard(self, a, b, ab):\n","    return ab / (a + b - ab);\n","\n","  def __kulczynski(self, a, b, ab):\n","    return (ab / a + ab / b) * 0.5\n","\n","  def show_result(self, a, b):\n","      number_of_coauthor = self.__count_coauthor([a, b])\n","      number_of_a = self.__count(a)\n","      number_of_not_a = self.__count(a, False)\n","      number_of_b = self.__count(b)\n","      number_of_not_b = self.__count(b, False)\n","      n = len(self.__itemsets)\n","      p_a = number_of_a / n\n","      p_b = number_of_b / n\n","      p_ab = number_of_coauthor / n\n","\n","      result = {\n","          \"Author A\": [a],\n","          \"Author B\": [b],\n","          \"support_count(A)\": [number_of_a],\n","          \"aupport_count(B)\": [number_of_b],\n","          \"Lift\": [self.__lift(p_a, p_b, p_ab)],\n","          \"X^2\": [self.__chi_square_test(number_of_a, number_of_b, number_of_not_a, number_of_not_b)],\n","          \"all confidence\": [self.__all_confidence(p_a, p_b, p_ab)],\n","          \"max confidence\": [self.__max_confidence(p_a, p_b, p_ab)],\n","          \"cosine\": [self.__cosine(p_a, p_b, p_ab)],\n","          \"jaccard\": [self.__jaccard(p_a, p_b, p_ab)],\n","          \"kulczynski\": [self.__kulczynski(p_a, p_b, p_ab)],\n","      }\n","\n","      return pd.DataFrame(result)\n","      \n","pe = PatternEvaluation(dataset)\n","pe.show_result(\"Soon Xin Ng\", \"Lajos Hanzo\")\n"]},{"cell_type":"markdown","source":["從前一題用 FP Growth 挖掘的結果我們可以發現，每個作者的論文數量只有幾百或幾千篇而已，但是 DBLP 這個資料集包含了大約 300 萬篇的論文資料，代表 null transaction 的數量非常多。如果我們是用 Lift 或 $x^2$ 來判斷的話，這兩種測量的形式會受 null trasaction 影響，在 null trasaction 數量那麼多的情況下，不適合用這兩種測量的數值來觀察，所以我們應該使用其他 null-invariant 的測量方式，像是 all confidence, max confidence, jaccard, cosine 和 kulczynski"],"metadata":{"id":"xS8JmPN3AZxN"}}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}